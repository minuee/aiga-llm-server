# app/common/entity_analyzer.py
import json
import re
from ..common.logger import logger
from typing import List, Dict, Any, Optional

from langchain_core.messages import BaseMessage, ToolMessage, HumanMessage
from langchain_openai import AzureChatOpenAI

# ğŸš¨ ì¶”ê°€: location_dicì—ì„œ SIDO_NAMES, GROUP_NAMES ì„í¬íŠ¸
from ..tools.location_dic import SIDO_NAMES, GROUP_NAMES

def _add_unique_items(target_list: List[str], items_to_add: Optional[Any]):
    """
    Helper function to add string items to a list while ensuring uniqueness.
    Filters out None or empty strings.
    """
    if not items_to_add:
        return
    
    if not isinstance(items_to_add, list):
        items_to_add = [items_to_add]

    for item in items_to_add:
        if isinstance(item, str) and item and item not in target_list:
            target_list.append(item)

def _add_unique_doctors(target_list: List[Dict[str, Any]], doctors_to_add: List[Dict[str, Any]]):
    """
    Helper to add doctor objects to a list, ensuring uniqueness based on (name, hospital) tuple.
    """
    existing_doctors = {(doc.get('name'), doc.get('hospital')) for doc in target_list}

    for doc in doctors_to_add:
        name = doc.get('name')
        hospital = doc.get('hospital')
        
        if name and (name, hospital) not in existing_doctors:
            target_list.append(doc)
            existing_doctors.add((name, hospital))


async def _extract_entities_from_text(llm: AzureChatOpenAI, text: str) -> Dict[str, List[str]]:
    """
    Uses a lightweight LLM call to extract key medical entities from raw user text.
    """
    # logger.info(f"Attempting to extract entities from user text: '{text}'")
    
    prompt = f"""ì‚¬ìš©ìì˜ ë¬¸ì¥ì—ì„œ 'ì§ˆë³‘', 'ì§„ë£Œê³¼', 'ë³‘ì›', 'ì˜ì‚¬', 'ì§€ì—­' ì´ë¦„ì„ ì¶”ì¶œí•˜ì„¸ìš”.
- disease: ì§ˆë³‘ ë˜ëŠ” ì¦ìƒì˜ ì´ë¦„.
- department: ì§„ë£Œê³¼ì˜ ì´ë¦„.
- hospital: ë³‘ì›ì˜ ì´ë¦„.
- doctor: ì˜ì‚¬ë¡œ ì¶”ì •ë˜ëŠ” ì‚¬ëŒì˜ ì´ë¦„.
- location: ì§€ì—­ì˜ ì´ë¦„ (ì˜ˆ: 'ì„œìš¸', 'ê°•ë‚¨êµ¬'). **ë³‘ì› ì´ë¦„ì— í¬í•¨ëœ ì§€ì—­ëª…(ì˜ˆ: 'ì„œìš¸ëŒ€ë³‘ì›'ì˜ 'ì„œìš¸')ì€ 'location'ìœ¼ë¡œ ë¶„ë¥˜í•˜ì§€ ë§ˆì„¸ìš”. 'location'ì€ ì˜¤ì§ ë…ë¦½ì ì¸ ì§€ì—­ ëª…ì¹­ì¼ ë•Œë§Œ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.**
ë°˜ë“œì‹œ ì•„ë˜ ì˜ˆì‹œì™€ ê°™ì´, ì¶”ì¶œëœ ì´ë¦„ì„ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ í¬í•¨í•˜ëŠ” JSON ê°ì²´ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
[ì˜ˆì‹œ 1]
Sentence: "ê°„ì•” ëª…ì˜ ì¶”ì²œí•´ì¤˜"
JSON: {{"diseases": ["ê°„ì•”"], "departments": [], "hospitals": [], "doctors": [], "location": null}}
[ì˜ˆì‹œ 2]
Sentence: "í—ˆë¦¬ ë””ìŠ¤í¬ë¡œ ê³ ìƒì¤‘ì¸ë°, ì„œìš¸ ìš°ë¦¬ë“¤ë³‘ì› ê¹€ì² ìˆ˜ ì˜ì‚¬ ì–´ë•Œ?"
JSON: {{"diseases": ["í—ˆë¦¬ ë””ìŠ¤í¬"], "departments": [], "hospitals": ["ìš°ë¦¬ë“¤ë³‘ì›"], "doctors": ["ê¹€ì² ìˆ˜"], "location": "ì„œìš¸"}}
[ì˜ˆì‹œ 3]
Sentence: "ì„œìš¸ëŒ€ë³‘ì›ì—ì„œ ì¹˜ë£Œë°›ê³  ì‹¶ì–´ìš”. ì‹¬ì¥ë‚´ê³¼ ì„ ìƒë‹˜ì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”."
JSON: {{"diseases": [], "departments": ["ì‹¬ì¥ë‚´ê³¼"], "hospitals": ["ì„œìš¸ëŒ€ë³‘ì›"], "doctors": [], "location": null}}
[ì˜ˆì‹œ 4]
Sentence: "ì„œìš¸ì—ì„œ ì„œìš¸ëŒ€ë³‘ì› ì‹¬ì¥ë‚´ê³¼ ì„ ìƒë‹˜ì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”."
JSON: {{"diseases": [], "departments": ["ì‹¬ì¥ë‚´ê³¼"], "hospitals": ["ì„œìš¸ëŒ€ë³‘ì›"], "doctors": [], "location": "ì„œìš¸"}}
[ì‹¤ì œ ì‘ì—…]
Sentence: "{text}"
JSON:"""

    try:
        response = await llm.ainvoke(prompt)
        cleaned_json_str = re.sub(r'```json\s*|\s*```', '', response.content.strip())
        entities = json.loads(cleaned_json_str)
        
        # locationì€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¯€ë¡œ ë³„ë„ë¡œ ì²˜ë¦¬
        extracted_location = None
        if "location" in entities:
            if isinstance(entities["location"], list) and len(entities["location"]) > 0:
                extracted_location = entities["location"][0]
            elif isinstance(entities["location"], str) and entities["location"] not in ["None", "null", ""]:
                extracted_location = entities["location"]

        for key in ["diseases", "departments", "hospitals", "doctors"]:
            if key not in entities or not isinstance(entities[key], list):
                entities[key] = []

        entities["location"] = extracted_location # ì¶”ì¶œëœ locationì„ ìµœì¢… í• ë‹¹


        # logger.info(f"LLM extracted entities from text: {entities}")
        return entities
    except Exception as e:
        # logger.error(f"Failed to extract entities from text with LLM: {e}", exc_info=True)
        return {"diseases": [], "departments": [], "hospitals": [], "doctors": [], "location": None}


async def update_entity_context(
    llm: AzureChatOpenAI,
    messages: List[BaseMessage]
) -> Optional[Dict[str, List[Any]]]: # Return type changed to Optional[Dict[str, List[Any]]]
    """
    Analyzes user queries and tool results to extract key medical entities from the current turn.
    It does not manage the history; it only extracts entities for the current turn.
    """
    
    logger.info("Starting entity extraction for current turn...")
    
    current_context = {"hospitals": [], "doctors": [], "departments": [], "diseases": [], "location": None}

    last_human_message: Optional[HumanMessage] = None
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            last_human_message = msg
            break
    
    tool_messages_for_turn = []
    if last_human_message:
        start_index = messages.index(last_human_message)
        for i in range(start_index + 1, len(messages)):
            msg = messages[i]
            if isinstance(msg, ToolMessage):
                tool_messages_for_turn.append(msg)
            elif isinstance(msg, HumanMessage): 
                break

    if last_human_message:
        logger.debug(f"Analyzing HumanMessage for entities: '{last_human_message.content}'")
        extracted_from_human = await _extract_entities_from_text(llm, last_human_message.content)
        _add_unique_items(current_context["diseases"], extracted_from_human.get("diseases"))
        _add_unique_items(current_context["departments"], extracted_from_human.get("departments"))
        _add_unique_items(current_context["hospitals"], extracted_from_human.get("hospitals"))
        current_context["location"] = extracted_from_human.get("location") # location ì¶”ê°€
        
        human_doctors_as_obj = [{"name": name, "hospital": None, "department": None} for name in extracted_from_human.get("doctors", [])]
        _add_unique_doctors(current_context["doctors"], human_doctors_as_obj)

    if tool_messages_for_turn:
        logger.info(f"Analyzing {len(tool_messages_for_turn)} ToolMessage(s) for entities...")
        for tool_message in tool_messages_for_turn:
            try:
                content = json.loads(tool_message.content)
                
                if content.get("migrated") is True:
                    logger.debug("ToolMessage is a migrated placeholder. Skipping entity extraction from it.")
                    continue

                answer = content.get("answer")
                if isinstance(answer, dict):
                    if answer.get("doctors") and isinstance(answer.get("doctors"), list):
                        docs = answer["doctors"]
                        tool_doctors_as_obj = [
                            {
                                "name": d.get("name"),
                                "hospital": d.get("hospital_name") or d.get("hospital"),
                                "department": d.get("deptname")
                            } for d in docs
                        ]
                        _add_unique_doctors(current_context["doctors"], tool_doctors_as_obj)

                        hospitals_from_docs = [d.get("hospital") for d in tool_doctors_as_obj if d.get("hospital")]
                        depts_from_docs = [d.get("department") for d in tool_doctors_as_obj if d.get("department")]
                        _add_unique_items(current_context["hospitals"], hospitals_from_docs)
                        _add_unique_items(current_context["departments"], depts_from_docs)

                    if answer.get("hospitals") and isinstance(answer.get("hospitals"), list):
                        hosps = answer["hospitals"]
                        _add_unique_items(current_context["hospitals"], [h.get("name") for h in hosps])
                        depts = [h.get("department") for h in hosps]
                        flat_depts = [item for sublist in depts if sublist for item in (sublist if isinstance(sublist, list) else [sublist])]
                        _add_unique_items(current_context["departments"], flat_depts)

                    _add_unique_items(current_context["diseases"], answer.get("disease"))
                    _add_unique_items(current_context["departments"], answer.get("department"))
                    _add_unique_items(current_context["hospitals"], answer.get("hospital"))
                    logger.info(f"Entities extracted from ToolMessage answer.")

            except (json.JSONDecodeError, TypeError):
                logger.warning("Could not parse ToolMessage content for entity extraction.")
            except Exception as e:
                logger.error(f"Unexpected error during ToolMessage entity extraction: {e}", exc_info=True)

    logger.info(f"Current turn entity snapshot: {current_context}")

    # Return current_context if it contains any extracted entities, otherwise None
    if any(current_context.values()):
        return current_context
    return None


async def extract_entities_for_routing(llm: AzureChatOpenAI, state: dict) -> dict:
    """
    Uses a fast LLM call to extract key entities for routing to a simpler tool, 
    considering the whole conversation context and pre-extracted entities,
    and also leveraging the persistent entity_history.
    """

    logger.info("Starting entity extraction for routing, considering full conversation history and entity_history.")

    # 1. ë¨¼ì € update_entity_contextë¥¼ í˜¸ì¶œí•˜ì—¬ í˜„ì¬ í„´ì˜ ê¸°ë³¸ì ì¸ ì—”í‹°í‹° ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    pre_extracted_entities = await update_entity_context(llm, state['messages'])
    

    # ì´ˆê¸° ì—”í‹°í‹° ì„¤ì •
    current_extracted = {
        "diseases": [],
        "departments": [],
        "hospitals": [],
        "doctors": [],
        "location": None # location í•„ë“œ ì¶”ê°€
    }

    if pre_extracted_entities: # pre_extracted_entitiesê°€ Noneì´ ì•„ë‹ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
        _add_unique_items(current_extracted["diseases"], pre_extracted_entities.get("diseases"))
        _add_unique_items(current_extracted["departments"], pre_extracted_entities.get("departments"))
        _add_unique_items(current_extracted["hospitals"], pre_extracted_entities.get("hospitals"))
        _add_unique_doctors(current_extracted["doctors"], pre_extracted_entities.get("doctors"))

    
    # ëŒ€í™” ê¸°ë¡ì„ LLM í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•˜ê¸° ìœ„í•´ í¬ë§·íŒ…
    def format_message_for_history(msg):
        if isinstance(msg, ToolMessage):
            try:
                # ToolMessageì˜ contentê°€ JSONì´ë©´ answer í•„ë“œë§Œ ì¶”ì¶œí•˜ì—¬ í¬í•¨
                content_json = json.loads(msg.content)
                if content_json.get("migrated") is True:
                     return "ToolMessage: [Previous tool result (migrated)]"
                elif content_json.get("answer"):
                    answer_content = content_json.get('answer')
                    if isinstance(answer_content, dict):
                        answer_to_send = answer_content.copy()
                        # Remove address-related keys to prevent LLM from misinterpreting location
                        for key in ['address', 'hospital_address', 'location']:
                            if key in answer_to_send:
                                del answer_to_send[key]
                        return f"ToolMessage (answer): {json.dumps(answer_to_send, ensure_ascii=False)}"
                    else:
                        # answer_contentê°€ dictê°€ ì•„ë‹Œ ê²½ìš° (ì˜ˆ: string) ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        return f"ToolMessage (answer): {json.dumps(answer_content, ensure_ascii=False)}"
                else:
                    return f"ToolMessage: {msg.content}"
            except json.JSONDecodeError:
                return f"ToolMessage: {msg.content}"
        else:
            return f"{type(msg).__name__}: {msg.content}"

    history_messages = [format_message_for_history(msg) for msg in state['messages'][-10:]] # ìµœê·¼ 10ê°œ ë©”ì‹œì§€
    history = "\n".join(history_messages)

    hospital_names = []
    if current_extracted.get('hospitals'):
        for item in current_extracted['hospitals']:
            if isinstance(item, dict) and item.get('name'):
                hospital_names.append(item['name'])
            elif isinstance(item, str):
                hospital_names.append(item)
    
    doctor_names = []
    if current_extracted.get('doctors'):
        for item in current_extracted['doctors']:
            if isinstance(item, dict) and item.get('name'):
                doctor_names.append(item['name'])
            elif isinstance(item, str):
                doctor_names.append(item)

    # LLM í”„ë¡¬í”„íŠ¸ì— í˜„ì¬ê¹Œì§€ ì¶”ì¶œëœ ì—”í‹°í‹° ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ì „ë‹¬
    prompt = f"""ì•„ë˜ ëŒ€í™” ê¸°ë¡ê³¼ í˜„ì¬ê¹Œì§€ ì¶”ì¶œëœ ì—”í‹°í‹° ì •ë³´ (í˜„ì¬ í„´ ë° persistent entity_historyì—ì„œ í†µí•©ë¨)ë¥¼ ëª¨ë‘ ì°¸ê³ í•˜ì—¬ 'location', 'disease', 'department', 'target'('ì˜ì‚¬' ë˜ëŠ” 'ë³‘ì›')ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
**í˜„ì¬ê¹Œì§€ ì¶”ì¶œëœ ì—”í‹°í‹° ì •ë³´ëŠ” ì•„ë˜ JSON ë¸”ë¡ìœ¼ë¡œ ì œê³µë˜ë©°, ì´ ì •ë³´ëŠ” ì‚¬ìš©ìì˜ ëª…ì‹œì ì¸ ì§ˆë¬¸ ë˜ëŠ” ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì—ì„œ í†µí•©ëœ ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì—”í‹°í‹° ë°ì´í„°ì…ë‹ˆë‹¤. LLMì€ ì´ ì •ë³´ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ í™œìš©í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤.**

[í˜„ì¬ê¹Œì§€ ì¶”ì¶œëœ ì—”í‹°í‹° (í†µí•© ì •ë³´)]
{{
    "diseases": {json.dumps(current_extracted['diseases'], ensure_ascii=False)},
    "departments": {json.dumps(current_extracted['departments'], ensure_ascii=False)},
    "hospitals": {json.dumps(hospital_names, ensure_ascii=False)},
    "doctors": {json.dumps(doctor_names, ensure_ascii=False)},
    "location": {json.dumps(current_extracted['location'], ensure_ascii=False)}
}}

[ê·œì¹™]
1. **ê·¸ë£¹ ì§€ì—­ëª… ì¸ì‹**: "ë¶€ìš¸ê²½", "ìˆ˜ë„ê¶Œ", "ì „ë¼ë„", "ê²½ìƒë„", "ì¶©ì²­ë„"ì™€ ê°™ì€ ê´‘ì—­ ê·¸ë£¹ ì´ë¦„ì€ 'location'ìœ¼ë¡œ ì¶”ì¶œë˜ì–´ì•¼ í•œë‹¤.
2. **ë§¤ìš° ì¤‘ìš”: 'ì†Œì•„ê³¼', 'ë‚´ê³¼', 'ì‹¬ì¥ë‚´ê³¼'ì™€ ê°™ì€ ì§„ë£Œê³¼ëª© ì´ë¦„ì€ ì ˆëŒ€ë¡œ 'disease' í•„ë“œì— ë„£ì§€ ë§ë¼. 'disease' í•„ë“œëŠ” 'ê°ê¸°', 'ê³ í˜ˆì••', 'ë‹¹ë‡¨'ì™€ ê°™ì€ ì‹¤ì œ ì§ˆë³‘ì´ë‚˜ ì¦ìƒ ì´ë¦„ë§Œ í¬í•¨í•´ì•¼ í•œë‹¤. ì§„ë£Œê³¼ëª©ì€ 'department' í•„ë“œì—ë§Œ í•´ë‹¹ëœë‹¤.**
   - **ë§Œì•½ 'disease'ê°€ ëª…í™•í•˜ê²Œ ì¶”ì¶œë˜ì—ˆë‹¤ë©´, í•´ë‹¹ ì§ˆë³‘ì„ ì£¼ë¡œ ë‹¤ë£¨ëŠ” ì§„ë£Œê³¼ëª©ì„ ìœ ì¶”í•˜ì—¬ 'department' í•„ë“œë¥¼ ì±„ì›Œ ë„£ì–´ë¼. ì˜ˆë¥¼ ë“¤ì–´, 'ì†Œì•„ ì•„í† í”¼ í”¼ë¶€ì—¼'ì´ diseaseë¼ë©´ 'í”¼ë¶€ê³¼'ë‚˜ 'ì†Œì•„ì²­ì†Œë…„ê³¼'ë¥¼ departmentë¡œ ìœ ì¶”í•  ìˆ˜ ìˆë‹¤.**
   - **ë§Œì•½ ì§ˆë³‘ëª…ë§Œ ìˆê³  ì§„ë£Œê³¼ëª© ìœ ì¶”ê°€ ì–´ë µë‹¤ë©´ 'department'ëŠ” nullë¡œ ì„¤ì •í•œë‹¤.**
3. 'ë‚´ ê·¼ì²˜', 'ì—¬ê¸° ê·¼ì²˜' ë“± ì‚¬ìš©ì ìì‹ ì„ ê¸°ì¤€ìœ¼ë¡œ í•˜ëŠ” ë‹¨ì–´ëŠ” 'location'ì´ ì•„ë‹ˆë‹¤. ì´ëŸ° ë‹¨ì–´ê°€ ë³´ì´ë©´ 'location'ì€ nullë¡œ ì„¤ì •í•´ë¼. ìµœì‹  ìˆœì˜ ëŒ€í™” íë¦„ì„ íŒë‹¨í•˜ì—¬ locationì„ ì¶”ì¶œí•´ì•¼ í•œë‹¤. ë³‘ì›ì •ë³´ì˜ í•´ë‹¹í•˜ëŠ” addressíŒŒë§ˆë¦¬í„°ë¥¼ ì ˆëŒ€ ì°¸ê³ í•˜ì§€ ë§ë¼.
4. 3ë²ˆì˜ ê²½ìš° íœ´ë¨¼ë©”ì‹œì§€ê°€ ì•„ë‹Œ AIê°€ ë‹µë³€í•œ ë©”ì‹œì§€ ë‚´ì—ì„œ ê°€ë ¹ "í˜„ì¬ ìœ„ì¹˜ ê·¼ì²˜ì—ì„œ" ë“±ì˜ ì‚¬ìš©ì ìì‹ ì„ ê¸°ì¤€ìœ¼ë¡œ í•˜ëŠ” ë‹¨ì–´ëŠ” 'location'ì„ nullë¡œ ì„¤ì •í•´ë¼.
5. ëŒ€í™” ê¸°ë¡ì—ì„œ ì´ë¯¸ 'ì‹œ/ë„' ì •ë³´(ì˜ˆ: ì„œìš¸)ê°€ ì–¸ê¸‰ë˜ì—ˆê³ , ë§ˆì§€ë§‰ ì§ˆë¬¸ì— 'êµ¬/ë™' ì •ë³´(ì˜ˆ: ì¤‘êµ¬)ë§Œ ìˆë‹¤ë©´, ì´ ë‘˜ì„ ì¡°í•©í•˜ì—¬ 'ì„œìš¸ ì¤‘êµ¬'ì™€ ê°™ì´ ì™„ì „í•œ ì§€ì—­ëª…ì„ 'location'ìœ¼ë¡œ ì¶”ì¶œí•´ì•¼ í•œë‹¤.
6. **ëŒ€í™”ì˜ ì „ì²´ ë§¥ë½ì„ ê³ ë ¤í•˜ì„¸ìš”. ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ ì§ˆë¬¸ì— íŠ¹ì • ì •ë³´(ì˜ˆ: ì§„ë£Œê³¼)ê°€ ì—†ë‹¤ë©´, ì´ì „ ëŒ€í™”ë“¤ì—ì„œ í•´ë‹¹í•˜ëŠ” ê°€ì¥ ìµœì‹  ì •ë³´ë¥¼ ì°¾ì•„ ì‚¬ìš©í•´ì•¼ í•œë‹¤.**
7. ** ì–´ë–¤ ê²½ìš°ì—ë„ 'target'ì€ nullì´ ë  ìˆ˜ ì—†ìœ¼ë©°, ë°˜ë“œì‹œ 'ì˜ì‚¬' ë˜ëŠ” 'ë³‘ì›' ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤.**
   - **ëŒ€í™” ê¸°ë¡ì„ ì°¸ê³ í•˜ì—¬ ì„¤ì •í•œë‹¤.
[ì˜ˆì‹œ]
ëŒ€í™” ê¸°ë¡:
HumanMessage: ì†Œì•„ ì•„í† í”¼ í”¼ë¶€ì—¼ ì „ë¬¸ì˜ ì¶”ì²œ

JSON:
{{
  "location": null,
  "disease": "ì†Œì•„ ì•„í† í”¼ í”¼ë¶€ì—¼",
  "department": ["í”¼ë¶€ê³¼", "ì†Œì•„ì²­ì†Œë…„ê³¼"],
  "target": "ì˜ì‚¬",
  "target_reason" : "ì „ë¬¸ì˜ë¥¼ ì¶”ì²œí•´ë‹¬ë¼ê³  ìš”ì²­ì„ í•´ì‚¬"
}}

ëŒ€í™” ê¸°ë¡:
HumanMessage: ê¸°ì¹¨ì´ ì‹¬í•œë°, ë‚´ ê·¼ì²˜ ë³‘ì› ì•Œë ¤ì¤˜

JSON:
{{
  "location": null,
  "disease": "ê¸°ì¹¨",
  "department": ["í˜¸í¡ê¸°ë‚´ê³¼"],
  "target": "ë³‘ì›",
  "target_reason" : "ê·¼ì²˜ ë³‘ì›ì„ ì•Œë ¤í•´ë‹¬ë¼ê³  ìš”ì²­ì„ í•´ì‚¬"
}}

[ëŒ€í™” ê¸°ë¡]
{history}

JSON ê°ì²´ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ê°’ì´ ì—†ìœ¼ë©´ nullì„ ì‚¬ìš©í•œë‹¤.
JSON:
        
"""
    try:
        response = await llm.ainvoke(prompt)
        logger.debug(f"Entity extraction for routing raw response: {response.content}")
        cleaned_json_str = re.sub(r'```json\s*|\s*```', '', response.content.strip())
        entities = json.loads(cleaned_json_str)

        if not isinstance(entities, dict):
            return {}
        
        target_reason = entities.get("target_reason")
        logger.info(f"llm target_reason : {target_reason}")
        # --- End: Robust Target Determination Logic ---
        
        # LLMì˜ ì‘ë‹µì—ì„œ ì¶”ì¶œëœ ê°’ë“¤ì„ í†µí•©, 'disease'ë¥¼ 'diseases' ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬
        final_entities = {
            "location": entities.get("location") if entities.get("location") not in [None, "", "null", "None"] else None,
            "diseases": [], # 'diseases'ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
            "department": [], # departmentëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ ì‹œì‘
            "hospitals": [], # hospitals ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
            "doctors": [], # doctors ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
            "target":  entities.get("target") or "ì˜ì‚¬"
        }
        # LLMì´ ë°˜í™˜í•œ departmentì™€ diseaseë¥¼ ê°ê°ì˜ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        _add_unique_items(final_entities["department"], entities.get("department"))
        _add_unique_items(final_entities["diseases"], entities.get("disease"))



        # ë¯¼ì§±ë‹˜ê»˜ì„œ ì£¼ì‹  ìš°ì„ ìˆœìœ„ ë³´ê°• ë¡œì§ (department -> hospital -> disease -> doctors) ì ìš©
        # ì´ ë¡œì§ì€ LLM ì¶”ì¶œ ê²°ê³¼ ë˜ëŠ” entity_historyì—ì„œ ë³´ê°•ëœ final_entitiesì— ëŒ€í•´ ì ìš©ë©ë‹ˆë‹¤.



        # location_historyë¥¼ í†µí•œ location ë³´ê°• ë¡œì§ì€ ì™„ì „íˆ ì œê±°í•¨.
        # final_entities["location"]ì€ ì´ë¯¸ LLM ì¶”ì¶œ ë˜ëŠ” is_only_target_from_llm ì¡°ê±´ì—ì„œ entity_history ë³´ê°•ì„ í†µí•´ ì„¤ì •ë¨.
        # targetì€ LLMì´ ìš°ì„ ì ìœ¼ë¡œ ê²°ì •í•˜ë„ë¡ í•˜ê³ , 4ìˆœìœ„ ê·œì¹™ì— ë”°ë¼ 'ì˜ì‚¬'ë¡œ í´ë°±ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì¶”ê°€ ë³´ê°•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

        logger.info(f"Extracted entities for routing: {final_entities}")
        return final_entities
    except Exception as e:
        logger.error(f"Entity extraction for routing failed: {e}", exc_info=True)
        return {}


async def extract_entities_for_routing_only_find_dept(llm: AzureChatOpenAI, state: dict) -> str | None:
    """
    Uses a targeted LLM call to extract only the latest 'department' from the conversation history,
    leveraging the persistent entity_history as well.
    """
    logger.info("Attempting to extract department with a specialized function...")
    
    # entity_historyë¥¼ stateì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    entity_history = state.get("entity_history", {"hospitals": [], "doctors": [], "departments": [], "diseases": [], "location": None})

    def format_message_for_history(msg):
        if isinstance(msg, ToolMessage):
            return "ToolMessage: [Previous tool result]"
        else:
            return f"{type(msg).__name__}: {msg.content}"

    history_messages = [format_message_for_history(msg) for msg in state['messages'][-10:]]
    history = "\n".join(history_messages)

    # entity_historyì—ì„œ departments ì •ë³´ë¥¼ ê°€ì ¸ì™€ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
    entity_history_depts_info = ""
    if entity_history["departments"]:
        entity_history_depts_info = f"\n[Previous confirmed departments from entity_history]: {', '.join(entity_history['departments'])}"

    prompt = f"""You are a specialized entity extractor. Your only task is to find the most recently mentioned medical department from the conversation history provided below.
Also consider the previously confirmed departments from the entity_history.

[Conversation History]
{history}
{entity_history_depts_info}

[Instructions]
1. Read the entire conversation history AND the previously confirmed departments.
2. Identify the medical department (e.g., 'ê°€ì •ì˜í•™ê³¼', 'ì†Œì•„ê³¼', 'ë‚´ê³¼').
3. If a department is mentioned, return only the name of the most recently mentioned or confirmed department.
4. If no department is mentioned or confirmed, return the word "None".
5. Do not provide any explanation or extra text. Only return the department name or "None".

Most recent department:"""
    
    try:
        response = await llm.ainvoke(prompt)
        department = response.content.strip()
        logger.debug(f"Specialized department extraction raw response: {department}")

        if department and department not in ["None", "null", ""]:
            logger.info(f"Specialized extractor found department: '{department}'")
            return department
        else:
            # ë§Œì•½ LLMì´ departmentë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆì§€ë§Œ entity_historyì— departmentê°€ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
            if entity_history["departments"]:
                logger.info(f"LLM did not find department, but using latest from entity_history: '{entity_history['departments'][-1]}'")
                return entity_history['departments'][-1]
            logger.info("Specialized extractor did not find a department, and entity_history is also empty.")
            return None
    except Exception as e:
        logger.error(f"Specialized department extraction failed: {e}", exc_info=True)
        return None


async def extract_entities_from_ai_response_and_update_history(
    llm: AzureChatOpenAI,
    ai_response_content: str,
    current_entity_history: Dict[str, List[Any]] # í˜„ì¬ entity_historyë¥¼ ë°›ì•„ì„œ ì—…ë°ì´íŠ¸
) -> Dict[str, List[Any]]:
    """
    Extracts key medical entities from an AI's final response (content)
    and updates the entity history.
    """
    extracted_from_ai_response = await _extract_entities_from_text(llm, ai_response_content)

    # current_entity_historyê°€ Noneì¼ ê²½ìš° ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ˆê¸°í™”
    if current_entity_history is None:
        current_entity_history = {"hospitals": [], "doctors": [], "departments": [], "diseases": [], "location": None}

    _add_unique_items(current_entity_history["diseases"], extracted_from_ai_response.get("diseases"))
    _add_unique_items(current_entity_history["departments"], extracted_from_ai_response.get("departments"))
    _add_unique_items(current_entity_history["hospitals"], extracted_from_ai_response.get("hospitals"))
    
    current_entity_history["location"] = extracted_from_ai_response.get("location")
    # ì˜ì‚¬ ì •ë³´ëŠ” ê°ì²´ í˜•íƒœë¡œ ì €ì¥ë˜ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬
    ai_doctors_as_obj = [{"name": name, "hospital": None, "department": None} for name in extracted_from_ai_response.get("doctors", [])]
    _add_unique_doctors(current_entity_history["doctors"], ai_doctors_as_obj)

    logger.info(f"Updated entity history after AI response: {current_entity_history}")
    return current_entity_history